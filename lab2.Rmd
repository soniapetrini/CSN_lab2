---
title: "CSN_lab2"
output: html_notebook
---

# Analysis of nodes degree distribution 

After finding the parameters and the best model, plot the data and a theoretical curve to see if there is sufficient agreement 

("I give x and y, use a double log scale for viz")

```{r}
library(ggplot2)
require("stats4") # for MLE
require("VGAM")

```


Degree sequence of the English network

```{r}
#degree_sequence = read.table("./data/English_degree_sequence.txt",
#                  header = FALSE)
#nrow(degree_sequence)   # number of nodes 
#sum(degree_sequence)    # sum of total degrees
#sum(degree_sequence)/dim(degree_sequence)[1]    # mean degree
#spectrum <- table(degree_sequence)
```

```{r}
#barplot(spectrum, main = "English",
#        xlab = "degree", ylab = "number of vertices")
```

```{r}
#barplot(spectrum, main = "English",
#        xlab = "degree", ylab = "number of vertices", log = "xy")
```


### TO FIX 

```{r}
#source("summary_table.R")
```

```{r}
write_summary <- function(language,file) {
    degree_sequence = read.table(file, header = FALSE)
    return(c(language,
             length(degree_sequence$V1),
             max(degree_sequence$V1),
             sum(degree_sequence$V1)/length(degree_sequence$V1),
             length(degree_sequence$V1)/sum(degree_sequence$V1)))
}
```



# IN-DEGREE DISTRIBUTION

Table 1: Summary of the properties of the degree sequences. N is the number of nodes, M/N is mean degree where M is the sum of degrees.

### Collect the node degree of every language

```{r}
source = read.table("list_in.txt", header = TRUE, 
         as.is = c("language","file"))

degree_distrib_ls = c()

for (x in 1:nrow(source)) {
    degree_distrib_ls[x] = read.table(source$file[x])
}


```

## Fitting Distributions


### Find starting parameter
# For gammma_1 and gamma_2, we can fit a lin reg of log(f(k)) over log(k), we measure probability thorugh sequence 


### Opt parameters with MLE

```{r}

get_mle_params <- function(x) {
    # global variables
    M <- sum(x)
    N <- length(x)
    M_1 <- sum(log(x))
    H <- function(kmax,gamma) {
    s <- 0
    for (i in 1:kmax) {
      s <- s + (1/(x[i]^gamma))
      }
    return(s)
    }
    
    ## Poisson
    minus_log_like_poisson <- function(lambda) {
      C <- 0;
      for(i in 1:N) {
        for(j in 2:x[i]) {
          C<-C+log(j)
        }
      }
      return(- M * log(lambda) + N*(lambda + log(1-(exp(-lambda)))) + C)
    }
    
    
    ## Geometric
    minus_log_like_geom <- function(q) {
      - (M-N)*log(1-q) - N*log(q)
    }
    
    ## zeta
    minus_log_like_zeta <- function(gamma) {
      N * log(zeta(gamma)) + gamma * M_1
    }
    
    ## Trunc Zeta
    minus_log_like_trunc_zeta <- function(kmax,gamma) {
      gamma*M_1 + N*log(H(kmax,gamma))
    }

    # ml estimation
    
    mle_geom <- mle(minus_log_like_geom,start = list(q = N/M),method = "L-BFGS-B",
                    lower = c(0.00001),upper = c(0.99999))
    
    mle_zeta <- mle(minus_log_like_zeta,start = list(gamma = 2),method = "L-BFGS-B",
                    lower = c(1.0000001))
    
    mle_poisson <- mle(minus_log_like_poisson,start = list(lambda = M/N),method = "L-BFGS-B",
                       lower = c(0.0000001))
    
    mle_trunc_zeta <- mle(minus_log_like_trunc_zeta,start = list(gamma = 2,kmax=max(x)),method = "L-BFGS-B",
                          lower = c(1.0000001,max(x)-1000),
                          upper=c(50,max(x)+1000))
    
    mle_ls <- c(mle_poisson,mle_geom,mle_zeta,mle_trunc_zeta)
    
    
    # collect the best par for each distribution
    best_pars <- c()
    i <- 1
    for (n in mle_ls) {
      best_pars[i] <- attributes(summary(n))$coef[1]
      i <- i + 1
    }
    
    
    # collect -2logLike 
    m2loglik_ls <- c()
    i <- 1
    for (n in mle_ls) {
      m2loglik_ls[i] <- m2logL <- attributes(summary(n))$m2logL
      i <- i + 1
    }

    
    return(list(best_pars,m2loglik_ls))
    
}

```


### Lang-Par table
```{r}
params_table <- data.frame()

for (n in 1:length(degree_distrib_ls)) {
    x <- unlist(degree_distrib_ls[[n]])
    new_pars <- get_mle_params(x)
    params_table <- rbind(params_table,new_pars[[1]])
}

params_table$lang <- source$language
colnames(params_table) <- c("lambda","q","gamma_1","gamma_2","kmax","lang")

```

# Model Selection

## Compute AICs

```{r}
get_AIC <- function(m2logL,K,N) {
   m2logL + 2*K*N/(N-K-1) # AIC with a correction for sample size
}


aic_table <- data.frame()

for (n in 1:length(degree_distrib_ls)) {
    x <- unlist(degree_distrib_ls[[n]])
    new_pars <- get_mle_params(x)
    
    N <- length(x)
    M <- sum(x)
    M_1 <- sum(log(x))
    minus_log_likelihood_zeta2 <- 2*M_1 - N * log((pi^2)/6)
    
    aic_poiss <- get_AIC(new_pars[[2]][1],1,N)
    aic_geom <- get_AIC(new_pars[[2]][2],1,N)
    aic_zeta <- get_AIC(new_pars[[2]][3],1,N)
    aic_trunc_zeta <- get_AIC(new_pars[[2]][4],2,N)
    aic_zeta_2 <- get_AIC(2*minus_log_likelihood_zeta2,0,N)
    
    aic_ls <- c(aic_poiss,aic_geom,aic_zeta,aic_trunc_zeta,aic_zeta_2)
    aic_table <- rbind(aic_table,aic_ls)
    aic_table$best <- which.min(aic_table[n,])
}
aic_table$lang <- source$language
colnames(aic_table) <- c("Poisson","Geometric","Zeta","Trunc_Zeta","Zeta_2","best","lang")
aic_table
```
## AICs Differences

```{r}
aic_diff_table <- data.frame("aic_min" = apply(aic_table[,c(1:5)],1,FUN=min))
```




### compare with real distributions
```{r}
degree_sequence = read.table("./samples_from_discrete_distributions/data/sample_of_geometric_with_parameter_0.2.txt",
                             header = FALSE)
```









